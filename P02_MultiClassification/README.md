# Animal Multi-classification | Multi-classification des animaux

This project uses 3 datasets to do 3 tasks:
* Stage 1: classification of animal classes - to predict that the target is a mammal or bird
* Stage 2: classification of species - to predict that the target is a rabbit, rat or chick
* Stage 3: multi-classification - to predict the class and the species at the same time

### 1. Structure of project
A. Datasets
    * Structure of dataset: number of images
      * train
        * chicken: 310
        * rabbits: 310
        * rats: 270
        
      * val
        * chicken: 30
        * rabbits: 30
        * rats: 20
        
    * Images-rename.py: rename images in bulk
    
B. Stage_1 Classes_classification
    * Classes_make_anno.py: generate annotations for train and test dataset; choose rabbits and chicken as datasets and predict whether the image shows a mammal or bird (0, 1)

    * Classes_Network.py: network for classes classification

    * Classes_classification.py: main file for training model and evaluation and calling trained model to do prediction, including result visualization

    * Classes_train_annotation.csv/Classes_val_annotation.csv: annotations for classes classification (generated by Classes_make_anno.py)

C. Stage_2 Species_classification
    * Species_make_anno.py: generate species annotations for train and test dataset of rabbits, rats and chicken (0, 1, 2)
  
    * Species_Network.py: network for species classification
  
    * Species_classification.py: main file for training model and evaluation and calling trained model to do prediction, including result visualization
  
    * Species_train_annotation.csv/Species_val_annotation.csv: annotations for species classification (generated by Species_make_anno.py)
  
D. Stage_3 Multi-classification
    * Multi_make_anno.py: generate both classes and species annotations for train and test dataset (0,0; 0,1; 0,2; 1,0; 1,1; 1,2)
    
    * Multi_Network.py: network for simultaneous classes and species classification
    
    * Multi_classification.py: main file for training model and evaluation and calling trained model to do prediction, including result visualization
    
    * Multi_train_annotation.csv/Multi_val_annotation.csv: annotations for classes and species classification (generated by Multi_make_anno.py)

### 2. Approach
##### A. Data preprocessing
Many deep learning applications require us to build the datasets of our own. In this project, these images of training and validation/test are grabbed from the Internet.

In Stage 1, mammal and bird data are labeled as 0 and 1.
In Stage 2, rabbits, rats and chicken are labelled as 0, 1 and 2.

##### B. Data loading
Using ___torchvision.transforms___ and ___torch.utils.data.DataLoader___ to load train data and test data.

Then define the data in different ways.  
In Stage 1:
> sample = {'image':image, 'classes':label_classes}

In Stage 2:
> sample = {'image':image, 'species':label_species}

In Stage 3:
> sample = {'image':image, 'classes':label_classes, 'species':label_species}

##### C. Data validation
Goal: validate the dataset and ensure that the images are correctly labeled.  
Method: display randomly an image and its label in the dataset before training a model.

##### D. Network building
Choose carefully the layers and their dimensions, and put them in appropriate positions.  
Stage 1 and Stage 2 are tasks of single classification, we can put a ___Softmax___ classifier behind the FC layer.  
Stage 3 is a task of multi-classification, we can connect 2 ___Softmax___ classifiers behind the FC layer, one is for classes classification and the other is for species classification.

##### E. Model training and testing
Train the model in train dataset and evaluate the model in test dataset, record separately the losses and accuracies, decide whether the training is effective and efficient, record the best model which has the highest accuracy.  
Stage 1 and Stage 2 are tasks of single classification, so the loss is of single classification.  
Stage 3 is a task of multi-classification, we can use linear weighted losses to calculate a final loss for training.  
Loss function: Cross Entropy Loss  
Optimization functions: SGD, Momentum, Adam, etc.

##### F. Parameter tuning
Tune the hyperparameters such as learning rate, momentum, weight of loss to optimize the result.

##### G. Data visualization
Predict images with the trained model so as to visualize directly the effect of the predictor.

### 3. Analysis

##### Environment of the project:
> OS: Windows 10  
> RAM: 16 GB  
> CPU: Intel Core i7-7700HQ 2.80GHz  
> GPU: Nvidia GeForce GTX 1050 __(PyTorch installed with CUDA enabled GPU)__   
> IDE: MS Visual Studio 2019 & VS Code  

##### Stage 1 and Stage 2: Manipulations
1. Create 3 networks:
    * The original network: conv, maxpool, relu, conv, maxpool, relu, fc, relu, dropout, fc, softmax
    * The original network + more layers: conv, maxpool, relu, conv, maxpool, relu, conv, maxpool, relu, fc, relu, dropout, fc, softmax
    * The original network + batch normaliation
2. Do grid search on learning rate, optimization method(SGD, Adam), and regularization. Save the results in png.
3. All the numbers of epoches are set to 30.
4. Remove softmax in the original net classes, since ___CrossEntropyLoss = Softmax + NLLLoss(Negative Log Likelihood Loss)___ contains Softmax already.

##### Stage 1 and Stage 2: Findings
1. Best result when the regularization is at 0, which means no regularization. Maybe it is because the dropout layer is sufficient.
2. For SGD, lr=0.01 is quite good for both classes and species classifications. Batch normalization can help convergence very slightly.
3. For Adam, lr=1e-4 may be helpful but the advantage is not very obvious.
4. Both SGD and Adam give similar results at the end.

##### Stage 3: Manipulations
1. Use 1 network:
    * The original network in Stage 1: conv, maxpool, relu, conv, maxpool, relu, fc, relu, dropout, fc, softmax
2. Try two types of minimization, one with loss=loss1+loss2*wt, with wt=1.0 and 1.5 (loss1 is for classes and loss2 is for species). The other one trys num_epoches1 first to minimize loss2, then try to minimize loss1.

##### Stage 3: Findings
1. No matter which type of minization is used, the accuracies converge to about 70% for classes and about 50% for species. The two-step method might be a little better. 
2. It seems that weight=1.5 is a little instable.

---
Ce projet utilise les 3 ensembles de données pour faire 3 tâches :
* Etape 1: classification de classes des animaux - pour prédire que ce soit un mammifère ou un oiseau
* Etape 2: classification d'espèces des animaux - pour prédire que ce soit un lapin, un rat ou un oiseau
* Etape 3: multi-classification - pour prédire la classe et l'espèce en même temps